{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: [('Logs',), ('Users',), ('LibraryLogs',)]\n",
      "Schema for table Logs:\n",
      "(0, 'id', 'INTEGER', 1, None, 1)\n",
      "(1, 'roll_number', 'VARCHAR(50)', 1, None, 0)\n",
      "(2, 'time', 'DATETIME', 1, None, 0)\n",
      "(3, 'mode', 'VARCHAR(50)', 1, None, 0)\n",
      "\n",
      "Schema for table Users:\n",
      "(0, 'id', 'INTEGER', 1, None, 1)\n",
      "(1, 'roll_number', 'VARCHAR(50)', 1, None, 0)\n",
      "(2, 'name', 'VARCHAR(100)', 1, None, 0)\n",
      "(3, 'designation', 'VARCHAR(50)', 1, None, 0)\n",
      "(4, 'year', 'INTEGER', 0, None, 0)\n",
      "\n",
      "Schema for table LibraryLogs:\n",
      "(0, 'id', 'INTEGER', 1, None, 1)\n",
      "(1, 'roll_number', 'VARCHAR(50)', 1, None, 0)\n",
      "(2, 'in_time', 'DATETIME', 1, None, 0)\n",
      "(3, 'out_time', 'DATETIME', 0, None, 0)\n",
      "(4, 'time_spent', 'INTEGER', 0, '0', 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the database (creates a new one if it doesn't exist)\n",
    "conn = sqlite3.connect(\"app-prod.sqlite\")\n",
    "\n",
    "# Create a cursor object to execute queries\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Execute a query to fetch all table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "print(\"Tables:\", tables)\n",
    "# Iterate through each table and print its schema\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    print(f\"Schema for table {table_name}:\")\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    schema = cursor.fetchall()\n",
    "    for column in schema:\n",
    "        print(column)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method of Moments Estimates:\n",
      "1st sample moment, E[X]: 455.90\n",
      "2nd sample moment, E[X^2]: 223161.63\n",
      "Estimated shape (a): 13.5697\n",
      "Estimated rate (b): 0.0298\n",
      "\n",
      "Maximum Likelihood Estimates:\n",
      "Estimated shape (a): 11.6488\n",
      "Estimated rate (b): 0.0256\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 1. Modeling Positive Data Using a Gamma Distribution\n",
    "#    with both MoM and MLE estimation.\n",
    "# -------------------------------\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import scipy.optimize as opt\n",
    "from scipy.special import psi  # digamma\n",
    "import math\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect(\"app-prod.sqlite\")\n",
    "np.random.seed(41)\n",
    "\n",
    "# Query to get visit_date and visitor_count, sorted by visitor_count\n",
    "# only for January and February \n",
    "query = \"\"\"\n",
    "SELECT DATE(in_time) AS visit_date, COUNT(DISTINCT roll_number) AS visitor_count\n",
    "FROM LibraryLogs\n",
    "WHERE strftime('%m', in_time) IN ('01', '02')\n",
    "GROUP BY visit_date\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load the result into a DataFrame\n",
    "cursor = conn.cursor()\n",
    "df_visitors_sorted = DataFrame(cursor.execute(query).fetchall(), columns=[\"visit_date\", \"visitor_count\"])\n",
    "\n",
    "# Select 30 random data points from the DataFrame\n",
    "random_data_points = df_visitors_sorted.sample(n=30, random_state=41)[\"visitor_count\"].to_numpy()\n",
    "\n",
    "# --- (a) Method of Moments (MoM) Estimates ---\n",
    "# Calculate sample mean and E[X^2]\n",
    "sample_mean = np.mean(random_data_points)\n",
    "sample_ex2 = np.mean(random_data_points**2)  # E[X^2]\n",
    "\n",
    "# Method of Moments (MoM) estimates\n",
    "a_mom = sample_mean**2 / (sample_ex2 - sample_mean**2)\n",
    "b_mom = sample_mean / (sample_ex2 - sample_mean**2) \n",
    "\n",
    "print(\"Method of Moments Estimates:\")\n",
    "print(\"1st sample moment, E[X]:\", f\"{sample_mean:.2f}\")\n",
    "print(\"2nd sample moment, E[X^2]:\", f\"{sample_ex2:.2f}\")\n",
    "print(\"Estimated shape (a):\", f\"{a_mom:.4f}\")\n",
    "print(\"Estimated rate (b):\", f\"{b_mom:.4f}\")\n",
    "\n",
    "# --- (b) Maximum Likelihood Estimation (MLE) ---\n",
    "# Define the log-likelihood function for the Gamma distribution\n",
    "def log_likelihood(params):\n",
    "    a, b = params\n",
    "    return np.sum((a - 1) * np.log(random_data_points) - random_data_points / b - a * np.log(b) - math.lgamma(a))\n",
    "\n",
    "# Initial guesses for a and b (using MoM estimates)\n",
    "initial_guess = [a_mom, b_mom]\n",
    "\n",
    "# Perform optimization to maximize the log-likelihood\n",
    "result = opt.minimize(\n",
    "    fun=lambda params: -log_likelihood(params),  # Minimize the negative log-likelihood\n",
    "    x0=initial_guess,\n",
    "    bounds=[(1e-6, None), (1e-6, None)]  # Ensure a and b are positive\n",
    ")\n",
    "\n",
    "# Extract the MLE estimates for a and b\n",
    "a_mle, b_mle = result.x\n",
    "\n",
    "print(\"\\nMaximum Likelihood Estimates:\")\n",
    "print(\"Estimated shape (a):\", f\"{a_mle:.4f}\")\n",
    "print(\"Estimated rate (b):\", f\"{1/b_mle:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval for Variance: [10049.91, 28634.80]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 2. Confidence Interval for Variance under a Normal Model\n",
    "# -------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import scipy.optimize as opt\n",
    "from scipy.special import psi  # digamma\n",
    "import math\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect(\"app-prod.sqlite\")\n",
    "np.random.seed(41)\n",
    "\n",
    "# Query to get visit_date and visitor_count, sorted by visitor_count\n",
    "# only for January and February \n",
    "query = \"\"\"\n",
    "SELECT DATE(in_time) AS visit_date, COUNT(DISTINCT roll_number) AS visitor_count\n",
    "FROM LibraryLogs\n",
    "WHERE strftime('%m', in_time) IN ('01', '02')\n",
    "GROUP BY visit_date\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load the result into a DataFrame\n",
    "df_visitors_sorted = DataFrame(cursor.execute(query).fetchall(), columns=[\"visit_date\", \"visitor_count\"])\n",
    "\n",
    "# Select 30 random data points from the DataFrame\n",
    "random_data_points = df_visitors_sorted.sample(n=30, random_state=41)[\"visitor_count\"].to_numpy()\n",
    "\n",
    "# Calculate sample variance\n",
    "sample_variance = np.var(random_data_points, ddof=1)  # unbiased sample variance\n",
    "n = len(random_data_points)  # sample size\n",
    "alpha = 0.05  # significance level for 95% confidence interval\n",
    "\n",
    "# Critical values for chi-square distribution\n",
    "chi2_lower = st.chi2.ppf(alpha / 2, df=n - 1)\n",
    "chi2_upper = st.chi2.ppf(1 - alpha / 2, df=n - 1)\n",
    "\n",
    "# Confidence interval for variance\n",
    "ci_variance_lower = (n - 1) * sample_variance / chi2_upper\n",
    "ci_variance_upper = (n - 1) * sample_variance / chi2_lower\n",
    "\n",
    "print(f\"95% Confidence Interval for Variance: [{ci_variance_lower:.2f}, {ci_variance_upper:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in Semester 03 dataset: 29\n",
      "Number of points in Semester 04 dataset: 31\n",
      "\n",
      "Semester 03 Visitors - Mean: 71.862 , Variance: 886.980\n",
      "Semester 04 Visitors - Mean: 70.452 , Variance: 844.656\n",
      "\n",
      "Confidence Interval for Difference of Means (Equal Variance Assumption): [-13.80, 16.62]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 3. Confidence Interval for the Difference in Means of Two Independent Normal Populations\n",
    "# -------------------------------\n",
    "# Query to find the number of visitors per day with roll number \"23BTECH\" in the month of November\n",
    "query_sem_03 = \"\"\"\n",
    "SELECT DATE(in_time) AS visit_date, COUNT(DISTINCT roll_number) AS visitor_count\n",
    "FROM LibraryLogs\n",
    "WHERE strftime('%m', in_time) = '11' AND roll_number LIKE '%23BTECH%'\n",
    "GROUP BY visit_date\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load the result into a DataFrame\n",
    "df_sem_03 = pd.DataFrame(cursor.execute(query_sem_03).fetchall(), columns=[\"visit_date\", \"visitor_count\"])\n",
    "\n",
    "# Query to find the number of visitors per day with roll number \"23BTECH\" in the month of January\n",
    "query_sem_04 = \"\"\"\n",
    "SELECT DATE(in_time) AS visit_date, COUNT(DISTINCT roll_number) AS visitor_count\n",
    "FROM LibraryLogs\n",
    "WHERE strftime('%m', in_time) = '01' AND roll_number LIKE '%23BTECH%'\n",
    "GROUP BY visit_date\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load the result into a DataFrame\n",
    "df_sem_04 = pd.DataFrame(cursor.execute(query_sem_04).fetchall(), columns=[\"visit_date\", \"visitor_count\"])\n",
    "\n",
    "# Convert data into numpy arrays\n",
    "visitors_sem_03 = df_sem_03[\"visitor_count\"].to_numpy()\n",
    "visitors_sem_04 = df_sem_04[\"visitor_count\"].to_numpy()\n",
    "\n",
    "# Calculate sample mean and variance for both datasets\n",
    "mean_sem_03 = np.mean(visitors_sem_03)\n",
    "variance_sem_03 = np.var(visitors_sem_03, ddof=1)\n",
    "\n",
    "mean_sem_04 = np.mean(visitors_sem_04)\n",
    "variance_sem_04 = np.var(visitors_sem_04, ddof=1)\n",
    "\n",
    "n_sem_03 = len(visitors_sem_03)\n",
    "n_sem_04 = len(visitors_sem_04)\n",
    "# Print the results\n",
    "print(\"Number of points in Semester 03 dataset:\", n_sem_03)\n",
    "print(\"Number of points in Semester 04 dataset:\", n_sem_04)\n",
    "print(\"\\nSemester 03 Visitors - Mean:\", f\"{mean_sem_03:.3f}\", \", Variance:\", f\"{variance_sem_03:.3f}\")\n",
    "print(\"Semester 04 Visitors - Mean:\", f\"{mean_sem_04:.3f}\", \", Variance:\", f\"{variance_sem_04:.3f}\")\n",
    "\n",
    "# Pooled variance\n",
    "pooled_variance = ((n_sem_03 - 1) * variance_sem_03 + (n_sem_04 - 1) * variance_sem_04) / (n_sem_03 + n_sem_04 - 2)\n",
    "\n",
    "# Standard error for the difference in means\n",
    "se_diff_equal_var = np.sqrt(pooled_variance * (1 / n_sem_03 + 1 / n_sem_04))\n",
    "\n",
    "# Critical t value for 95% confidence interval\n",
    "t_crit_equal_var = st.t.ppf(0.975, df=n_sem_03 + n_sem_04 - 2)\n",
    "\n",
    "# Confidence interval for the difference in means\n",
    "ci_diff_lower_equal_var = mean_sem_03 - mean_sem_04 - t_crit_equal_var * se_diff_equal_var\n",
    "ci_diff_upper_equal_var = mean_sem_03 - mean_sem_04 + t_crit_equal_var * se_diff_equal_var\n",
    "\n",
    "print(f\"\\nConfidence Interval for Difference of Means (Equal Variance Assumption): [{ci_diff_lower_equal_var:.2f}, {ci_diff_upper_equal_var:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size (n): 58\n",
      "Observed visits (X_obs): 23\n",
      "Critical value (k*): 36\n",
      "Accept H₀. Observed visits (23) < critical value (36).\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4. Hypothesis Testing for a Bernoulli-Distributed (Binary) Response\n",
    "# -------------------------------\n",
    "# Query to check if roll number \"AI23BTECH11022\" visited the library each day in January and February\n",
    "query_ai23btech = \"\"\"\n",
    "WITH all_dates AS (\n",
    "    SELECT DATE(in_time) AS visit_date\n",
    "    FROM LibraryLogs\n",
    "    WHERE strftime('%m', in_time) IN ('01', '02')\n",
    "    GROUP BY visit_date\n",
    ")\n",
    "SELECT all_dates.visit_date, \n",
    "       CASE WHEN COUNT(LibraryLogs.roll_number) > 0 THEN 1 ELSE 0 END AS visited\n",
    "FROM all_dates\n",
    "LEFT JOIN LibraryLogs \n",
    "ON all_dates.visit_date = DATE(LibraryLogs.in_time) \n",
    "   AND LibraryLogs.roll_number = 'AI23BTECH11022'\n",
    "GROUP BY all_dates.visit_date\n",
    "ORDER BY all_dates.visit_date;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load the result into a DataFrame\n",
    "df_ai23btech = pd.DataFrame(cursor.execute(query_ai23btech).fetchall(), columns=[\"visit_date\", \"visited\"])\n",
    "\n",
    "visited_array = df_ai23btech[\"visited\"].to_numpy()\n",
    "\n",
    "# Perform hypothesis testing for H0: p <= 0.5 vs H1: p > 0.5\n",
    "import pandas as pd\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Extract the binary array of visits\n",
    "n = len(visited_array)\n",
    "X_obs = visited_array.sum()  # Observed number of visits\n",
    "\n",
    "# Parameters\n",
    "p0 = 0.5\n",
    "alpha = 0.05\n",
    "\n",
    "# Find k* using the survival function\n",
    "k_star = None\n",
    "for k in range(n + 1):\n",
    "    # Compute P(X >= k) under p0 = 0.5\n",
    "    prob = binom.sf(k - 1, n, p0)\n",
    "    if prob <= alpha:\n",
    "        k_star = k\n",
    "        break\n",
    "\n",
    "# Hypothesis test conclusion\n",
    "if k_star is not None and X_obs >= k_star:\n",
    "    conclusion = f\"Reject H₀. Observed visits ({X_obs}) ≥ critical value ({k_star}).\"\n",
    "else:\n",
    "    conclusion = f\"Accept H₀. Observed visits ({X_obs}) < critical value ({k_star}).\"\n",
    "\n",
    "print(f\"Sample size (n): {n}\")\n",
    "print(f\"Observed visits (X_obs): {X_obs}\")\n",
    "print(f\"Critical value (k*): {k_star}\")\n",
    "print(conclusion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
